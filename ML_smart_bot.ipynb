{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNTDrZz7cf6aVl4w7RtaJ8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanjayBukka/ML-Smart-Bot/blob/main/ML_smart_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML Smart Bot"
      ],
      "metadata": {
        "id": "gAerdfkQFTlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set page configuration\n",
        "st.set_page_config(page_title=\"Advanced ML Analysis App\", layout=\"wide\")\n",
        "\n",
        "def load_data(file):\n",
        "    \"\"\"Load and prepare dataset\"\"\"\n",
        "    try:\n",
        "        if file.name.endswith('.csv'):\n",
        "            df = pd.read_csv(file)\n",
        "        elif file.name.endswith('.txt'):\n",
        "            df = pd.read_csv(file, delimiter='\\t')\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error loading file: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def preprocess_data(df, numeric_features, categorical_features):\n",
        "    \"\"\"Preprocess the data with scaling and encoding\"\"\"\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # Scale numeric features\n",
        "    if numeric_features:\n",
        "        scaler = StandardScaler()\n",
        "        df_processed[numeric_features] = scaler.fit_transform(df_processed[numeric_features])\n",
        "\n",
        "    # Encode categorical features\n",
        "    for col in categorical_features:\n",
        "        le = LabelEncoder()\n",
        "        df_processed[col] = le.fit_transform(df_processed[col])\n",
        "\n",
        "    return df_processed\n",
        "\n",
        "\n",
        "# Add this function after the preprocess_data function\n",
        "def prepare_correlation_data(df, features, target_column):\n",
        "    \"\"\"Prepare data for correlation by encoding categorical variables\"\"\"\n",
        "    df_corr = df.copy()\n",
        "\n",
        "    # Encode all categorical columns including target if it's categorical\n",
        "    for column in features + [target_column]:\n",
        "        if df_corr[column].dtype == 'object':\n",
        "            le = LabelEncoder()\n",
        "            df_corr[column] = le.fit_transform(df_corr[column])\n",
        "\n",
        "    return df_corr\n",
        "\n",
        "# Replace the correlation matrix section (around line 247) with this:\n",
        "try:\n",
        "    # Prepare data for correlation\n",
        "    df_corr = prepare_correlation_data(df, features, target_column)\n",
        "\n",
        "    # Calculate and display correlation matrix\n",
        "    st.write(\"#### Feature Correlation Matrix\")\n",
        "    corr = df_corr[features + [target_column]].corr()\n",
        "    fig = px.imshow(corr,\n",
        "                    title=\"Feature Correlation Matrix\",\n",
        "                    color_continuous_scale=\"RdBu\")\n",
        "    st.plotly_chart(fig)\n",
        "\n",
        "    # Feature correlations with target\n",
        "    correlations = df_corr[features + [target_column]].corr()[target_column].sort_values(ascending=False)\n",
        "    st.write(\"#### Top Feature Correlations with Target Variable:\")\n",
        "    st.write(correlations[1:])\n",
        "except Exception as e:\n",
        "    st.warning(\"Could not calculate correlations for some categorical variables.\")\n",
        "    st.write(\"This usually happens with categorical variables that cannot be meaningfully correlated.\")\n",
        "\n",
        "def get_model(algorithm, is_regression=True):\n",
        "    \"\"\"Return the selected model based on problem type\"\"\"\n",
        "    regression_models = {\n",
        "        \"Random Forest\": RandomForestRegressor(),\n",
        "        \"Linear Regression\": LinearRegression(),\n",
        "        \"Support Vector Machine\": SVR(),\n",
        "        \"Decision Tree\": DecisionTreeRegressor(),\n",
        "        \"K-Nearest Neighbors\": KNeighborsRegressor()\n",
        "    }\n",
        "\n",
        "    classification_models = {\n",
        "        \"Random Forest\": RandomForestClassifier(),\n",
        "        \"Logistic Regression\": LogisticRegression(),\n",
        "        \"Support Vector Machine\": SVC(probability=True),\n",
        "        \"Decision Tree\": DecisionTreeClassifier(),\n",
        "        \"K-Nearest Neighbors\": KNeighborsClassifier()\n",
        "    }\n",
        "\n",
        "    return regression_models[algorithm] if is_regression else classification_models[algorithm]\n",
        "\n",
        "def plot_regression_results(y_test, predictions):\n",
        "    \"\"\"Plot actual vs predicted values for regression\"\"\"\n",
        "    fig = px.scatter(x=y_test, y=predictions,\n",
        "                    labels={'x': 'Actual Values', 'y': 'Predicted Values'},\n",
        "                    title='Actual vs Predicted Values')\n",
        "    fig.add_shape(type='line',\n",
        "                 x0=min(y_test), y0=min(y_test),\n",
        "                 x1=max(y_test), y1=max(y_test),\n",
        "                 line=dict(color='red', dash='dash'))\n",
        "    return fig\n",
        "\n",
        "def plot_feature_importance(model, feature_names):\n",
        "    \"\"\"Plot feature importance for supported models\"\"\"\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        importance = model.feature_importances_\n",
        "    elif hasattr(model, 'coef_'):\n",
        "        importance = np.abs(model.coef_) if len(model.coef_.shape) == 1 else np.abs(model.coef_[0])\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': importance\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    fig = px.bar(importance_df,\n",
        "                 x='Feature',\n",
        "                 y='Importance',\n",
        "                 title='Feature Importance')\n",
        "    return fig\n",
        "\n",
        "# Main app title\n",
        "st.title(\"ðŸ¤– Advanced Machine Learning Analysis Application\")\n",
        "\n",
        "# File upload section\n",
        "st.header(\"1. Data Upload\")\n",
        "uploaded_file = st.file_uploader(\"Upload your dataset (CSV or TXT)\", type=['csv', 'txt'])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Load data\n",
        "    df = load_data(uploaded_file)\n",
        "\n",
        "    if df is not None:\n",
        "        # Data Preview\n",
        "        st.header(\"2. Data Preview\")\n",
        "        st.write(\"#### First few rows of the dataset\")\n",
        "        st.dataframe(df.head())\n",
        "\n",
        "        # Basic data info\n",
        "        st.write(\"#### Dataset Information\")\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            st.write(f\"Rows: {df.shape[0]}\")\n",
        "        with col2:\n",
        "            st.write(f\"Columns: {df.shape[1]}\")\n",
        "        with col3:\n",
        "            st.write(f\"Missing values: {df.isnull().sum().sum()}\")\n",
        "\n",
        "        # Feature Selection\n",
        "        st.header(\"3. Feature Selection\")\n",
        "\n",
        "        # Separate numeric and categorical columns\n",
        "        numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "        categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "        # Target variable selection\n",
        "        target_column = st.selectbox(\n",
        "            \"Select target variable\",\n",
        "            df.columns,\n",
        "            help=\"This is the variable you want to predict\"\n",
        "        )\n",
        "\n",
        "        # Determine if it's a regression or classification problem\n",
        "        is_regression = df[target_column].dtype in ['int64', 'float64'] and len(df[target_column].unique()) > 10\n",
        "\n",
        "        # Feature selection\n",
        "        st.write(\"#### Select Features\")\n",
        "        numeric_features = st.multiselect(\n",
        "            \"Select numeric features\",\n",
        "            [col for col in numeric_columns if col != target_column],\n",
        "            default=[col for col in numeric_columns if col != target_column][:3]\n",
        "        )\n",
        "\n",
        "        categorical_features = st.multiselect(\n",
        "            \"Select categorical features\",\n",
        "            [col for col in categorical_columns if col != target_column],\n",
        "            default=[col for col in categorical_columns if col != target_column][:2]\n",
        "        )\n",
        "\n",
        "        # Model Selection and Parameters\n",
        "        st.header(\"4. Model Configuration\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            if is_regression:\n",
        "                algorithm = st.selectbox(\n",
        "                    \"Select ML Algorithm\",\n",
        "                    [\"Random Forest\", \"Linear Regression\", \"Support Vector Machine\",\n",
        "                     \"Decision Tree\", \"K-Nearest Neighbors\"]\n",
        "                )\n",
        "            else:\n",
        "                algorithm = st.selectbox(\n",
        "                    \"Select ML Algorithm\",\n",
        "                    [\"Random Forest\", \"Logistic Regression\", \"Support Vector Machine\",\n",
        "                     \"Decision Tree\", \"K-Nearest Neighbors\"]\n",
        "                )\n",
        "\n",
        "        with col2:\n",
        "            test_size = st.slider(\"Test Set Size (%)\", 10, 50, 20)\n",
        "\n",
        "        # Run Analysis button\n",
        "        if st.button(\"ðŸš€ Run Analysis\"):\n",
        "            st.header(\"5. Analysis Results\")\n",
        "\n",
        "            # Prepare features and target\n",
        "            features = numeric_features + categorical_features\n",
        "            X = df[features]\n",
        "            y = df[target_column]\n",
        "\n",
        "            # Preprocess data\n",
        "            X_processed = preprocess_data(X, numeric_features, categorical_features)\n",
        "            if not is_regression and y.dtype == 'object':\n",
        "                le = LabelEncoder()\n",
        "                y = le.fit_transform(y)\n",
        "\n",
        "            # Split data\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X_processed, y, test_size=test_size/100, random_state=42\n",
        "            )\n",
        "\n",
        "            # Train model\n",
        "            model = get_model(algorithm, is_regression)\n",
        "            model.fit(X_train, y_train)\n",
        "            predictions = model.predict(X_test)\n",
        "\n",
        "            # Results visualization\n",
        "            if is_regression:\n",
        "                # Regression metrics\n",
        "                mse = mean_squared_error(y_test, predictions)\n",
        "                rmse = np.sqrt(mse)\n",
        "                r2 = r2_score(y_test, predictions)\n",
        "\n",
        "                st.write(\"#### Model Performance Metrics\")\n",
        "                col1, col2, col3 = st.columns(3)\n",
        "                with col1:\n",
        "                    st.metric(\"RÂ² Score\", f\"{r2:.3f}\")\n",
        "                with col2:\n",
        "                    st.metric(\"RMSE\", f\"{rmse:.3f}\")\n",
        "                with col3:\n",
        "                    st.metric(\"MSE\", f\"{mse:.3f}\")\n",
        "\n",
        "                # Actual vs Predicted Plot\n",
        "                st.write(\"#### Actual vs Predicted Values\")\n",
        "                fig = plot_regression_results(y_test, predictions)\n",
        "                st.plotly_chart(fig)\n",
        "            else:\n",
        "                # Classification metrics\n",
        "                st.write(\"#### Confusion Matrix\")\n",
        "                conf_matrix = confusion_matrix(y_test, predictions)\n",
        "                fig = px.imshow(conf_matrix,\n",
        "                               labels=dict(x=\"Predicted\", y=\"Actual\"),\n",
        "                               x=[str(i) for i in range(len(np.unique(y)))],\n",
        "                               y=[str(i) for i in range(len(np.unique(y)))],\n",
        "                               title=\"Confusion Matrix\",\n",
        "                               color_continuous_scale=\"Viridis\")\n",
        "                st.plotly_chart(fig)\n",
        "\n",
        "                st.write(\"#### Classification Report\")\n",
        "                report = classification_report(y_test, predictions, output_dict=True)\n",
        "                report_df = pd.DataFrame(report).transpose()\n",
        "                st.dataframe(report_df)\n",
        "\n",
        "            # Feature Importance\n",
        "            st.write(\"#### Feature Importance\")\n",
        "            importance_fig = plot_feature_importance(model, features)\n",
        "            if importance_fig:\n",
        "                st.plotly_chart(importance_fig)\n",
        "\n",
        "            # Correlation Matrix\n",
        "            st.write(\"#### Feature Correlation Matrix\")\n",
        "            corr = df[features + [target_column]].corr()\n",
        "            fig = px.imshow(corr,\n",
        "                           title=\"Feature Correlation Matrix\",\n",
        "                           color_continuous_scale=\"RdBu\")\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "            # Automated Insights\n",
        "            st.header(\"6. Automated Insights\")\n",
        "            if is_regression:\n",
        "                st.info(f\"\"\"\n",
        "                ðŸ“Š Model Performance Summary:\n",
        "                - RÂ² Score: {r2:.3f} (higher is better, 1 is perfect)\n",
        "                - Root Mean Squared Error: {rmse:.3f}\n",
        "                - Number of features used: {len(features)}\n",
        "                - Training set size: {len(X_train)} samples\n",
        "                - Test set size: {len(X_test)} samples\n",
        "                \"\"\")\n",
        "            else:\n",
        "                accuracy = report['accuracy']\n",
        "                st.info(f\"\"\"\n",
        "                ðŸ“Š Model Performance Summary:\n",
        "                - Overall Accuracy: {accuracy:.3f}\n",
        "                - Number of features used: {len(features)}\n",
        "                - Training set size: {len(X_train)} samples\n",
        "                - Test set size: {len(X_test)} samples\n",
        "                \"\"\")\n",
        "\n",
        "else:\n",
        "    st.info(\"ðŸ‘† Please upload a CSV or TXT file to begin the analysis\")\n",
        "    st.write(\"\"\"\n",
        "    #### This application supports:\n",
        "    - Both regression and classification problems\n",
        "    - Multiple ML algorithms\n",
        "    - Automated data preprocessing\n",
        "    - Feature importance analysis\n",
        "    - Correlation analysis\n",
        "    - Detailed performance metrics\n",
        "    \"\"\")"
      ],
      "metadata": {
        "id": "stKLIUDpDK5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43989baa-7572-4a32-b110-9923e23f7ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pandas numpy scikit-learn plotly seaborn matplotlib pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZAG1pHrBmrf",
        "outputId": "31a6e277-57e3-4e60-e0fc-fbc83aa6ee90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.41.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.18.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Downloading pyngrok-7.2.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kill any existing processes\n",
        "!killall ngrok\n",
        "!killall streamlit\n",
        "\n",
        "# Start Streamlit\n",
        "!streamlit run app.py &>/dev/null &\n",
        "\n",
        "# Wait a few seconds for Streamlit to start\n",
        "import time\n",
        "time.sleep(3)\n",
        "\n",
        "# Try connecting with ngrok again\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()  # Kill any existing ngrok processes\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Public URL: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or1FpvCXAtm0",
        "outputId": "dd152d76-b145-4a31-a7bc-8cb8b5ca29bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-01-07T18:43:12+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-8ec8c3b8-c7ec-4ac3-a960-353a8269415a acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-01-07T18:43:12+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8501-8ec8c3b8-c7ec-4ac3-a960-353a8269415a err=\"failed to start tunnel: session closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://a8dd-34-30-136-86.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}